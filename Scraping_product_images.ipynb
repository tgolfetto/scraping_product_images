{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eXN6OF6VzO4BlTRSNIkECxg8sTgH0Cdo",
      "authorship_tag": "ABX9TyPU6Bdp3sWojG1FaHjdNG/Q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Function to fetch a number of images (1 to N) for a specific product, using Google Images."
      ],
      "metadata": {
        "id": "TPRS1RgKJ2yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from random import randint\n",
        "from time import sleep\n",
        "\n",
        "# Headers to look less suspicios when scraping\n",
        "user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/602.2.14 (KHTML, like Gecko) Version/10.0.1 Safari/602.2.14'\n",
        "headers = {'User-Agent': user_agent,'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'}\n",
        "\n",
        "# Fetch a number {limit} of images from Google Images querying for {product}\n",
        "def fetch_product(product, limit):\n",
        "  # Sleep between 1 to 5 seconds to change the request pattern\n",
        "  sleep(randint(1,5))\n",
        "  # Google Images URL\n",
        "  url = f\"https://www.google.com/search?q={product}&tbm=isch\"\n",
        "  response = requests.get(url)\n",
        "  # Parse the HTML content\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "  #print(soup.prettify())\n",
        "  image_tags = soup.find_all('img', attrs={'class': 'DS1iW'}) # Class tag changes frequently\n",
        "  # Return the first {limit} images, if any\n",
        "  if image_tags:\n",
        "    result = []\n",
        "    for i in range(min(limit, len(image_tags))):\n",
        "      result.append(image_tags[i]['src'])\n",
        "    return result\n",
        "  else:\n",
        "    return [\"\"]"
      ],
      "metadata": {
        "id": "ooSicevlpxIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to fill the data into the map that will generate the Dataframe"
      ],
      "metadata": {
        "id": "XtqS4HI3K96q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From a path, return the HTML tag of an image sourcing it\n",
        "def path_to_image_html(path):\n",
        "  print(path)\n",
        "  return '<img src=\"' + path + '\" width=\"100\" >'\n",
        "\n",
        "# Fill the various data in the map that will be used for the Dataframe\n",
        "def fill_data(data, row, picture):\n",
        "  data['Image'].append(picture)\n",
        "  data['Season'].append(row['Season'])\n",
        "  data['Brand'].append(row['Brand'])\n",
        "  data['SKU'].append(row['SKU'])\n",
        "  data['Description'].append(row['Description'])\n",
        "  data['Style'].append(row['Style'])\n",
        "  data['Colour Code'].append(row['Colour Code'])\n",
        "  data['Colour Desc'].append(row['Colour Desc'])\n",
        "  data['Size'].append(row['Size'])\n",
        "  data['Gender'].append(row['Gender'])\n",
        "  data['Category'].append(row['Category'])\n",
        "  data['Sub-Category'].append(row['Sub-Category'])\n",
        "  data['DDP-EUR'].append(row['DDP-EUR'])\n",
        "  data['Alpi Servizio Moda'].append(row['Alpi Servizio Moda'])\n",
        "  data['Alpi UK'].append(row['Alpi UK'])"
      ],
      "metadata": {
        "id": "d265htakEYJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A CSV log is used to save the images that were scraped in the past."
      ],
      "metadata": {
        "id": "UUbwQqsDLjBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import csv\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the CSV log file on Google Drive\n",
        "log_file_path = '/content/drive/My Drive/Data/ATS_log.csv'\n",
        "\n",
        "log_map = {}\n",
        "\n",
        "# Fill the map containing SKU - Image path reading each line of the log\n",
        "with open(log_file_path, 'r') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "      if row['SKU'] not in log_map:\n",
        "        log_map[row['SKU']] = row['Image']"
      ],
      "metadata": {
        "id": "osgdj44Y_5UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the ATS file and fetch images for each product"
      ],
      "metadata": {
        "id": "y4NjGMEMd31D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5FvG9HAnBNA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import csv\n",
        "import pandas as pd\n",
        "from IPython.core.display import display,HTML\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the CSV file on Google Drive\n",
        "csv_file_path = '/content/drive/My Drive/Data/ATS_cut.csv'\n",
        "\n",
        "# Data to be print\n",
        "data = {\n",
        "    'Image': [],\n",
        "    'Season': [],\n",
        "    'Brand': [],\n",
        "    'SKU': [],\n",
        "    'Description': [],\n",
        "    'Style': [],\n",
        "    'Colour Code': [],\n",
        "    'Colour Desc': [],\n",
        "    'Size': [],\n",
        "    'Gender': [],\n",
        "    'Category': [],\n",
        "    'Sub-Category': [],\n",
        "    'DDP-EUR': [],\n",
        "    'Alpi Servizio Moda': [],\n",
        "    'Alpi UK': []\n",
        "}\n",
        "\n",
        "last_product_fetched = \"\"\n",
        "\n",
        "# Open the CSV file and read each line\n",
        "with open(csv_file_path, 'r') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "      # Only consider products in Italian warehouses\n",
        "      if row['Alpi Servizio Moda'] or row['Alpi UK']:\n",
        "        product = row['Brand'] + ' ' + row['Style'] # Text that will be queried\n",
        "        print(product)\n",
        "        # Only fetch new products, skip duplicate queries and data saved on the log\n",
        "        if product != last_product_fetched:\n",
        "          if row['SKU'] in log_map:\n",
        "            print('Reading from log')\n",
        "            picture = log_map[row['SKU']]\n",
        "            fill_data(data, row, picture)\n",
        "          else:\n",
        "            pictures = fetch_product(product, 1)\n",
        "            print('Fetched ' + pictures[0])\n",
        "            last_product_fetched = product\n",
        "            fill_data(data, row, path_to_image_html(pictures[0]))\n",
        "\n",
        "# Create a DataFrame from the data dictionary\n",
        "df = pd.DataFrame(data)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Save the DataFrame in HTML\n",
        "df.to_html('ATS.html', escape=False)\n",
        "\n",
        "# Save the DataFrame in CSV for logging purposes\n",
        "df.to_csv(log_file_path, index=False)\n"
      ]
    }
  ]
}